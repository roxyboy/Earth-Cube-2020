{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# In this notebook, we show the code for analysis.\n",
    "\n",
    "We would like to reconstruct Fig. 12 in [Wenegrat et al. (2018)](https://journals.ametsoc.org/doi/full/10.1175/JPO-D-17-0219.1) to see the relative importance of surface forcing on mode water formation in our submesoscale permitting North Atlantic simulation with tidal forcing (eNATL60). The spatial resolution is 1/60$^\\circ$ with 300 vertical layers allowing for well resolved eddies. The sea-surface data from a run without tidal forcing are available on [Pangeo](https://catalog.pangeo.io/browse/master/ocean/MEOM_NEMO/).\n",
    "\n",
    "The contributions due to turbulent thermal wind ($J_\\text{TTW}$), surface wind kinematic forcing ($J_\\text{wind}$) and buoyancy forcing ($J^\\text{buoy}_\\text{D}$) are diagnosed as: \n",
    "$$J_\\text{TTW} \\simeq -0.05H_\\text{ML}|\\overline{\\nabla_\\text{h}b}^z|^2,$$\n",
    "\n",
    "$$J_\\text{wind} \\simeq f\\frac{\\text{EBF}}{H_\\text{ML}} = \\frac{({\\bf \\tau}^w\\times {\\bf k})\\cdot \\overline{\\nabla_\\text{h}b}^z}{\\rho H_\\text{ML}} = \\frac{\\tau^y\\overline{b_x}^z - \\tau^x\\overline{b_y}^z}{\\rho H_\\text{ML}}$$\n",
    "where $\\text{EBF} = \\frac{1}{\\rho f}({\\bf \\tau}^w\\times {\\bf k})\\cdot\\overline{\\nabla_\\text{h}b}^z$ is the Ekman buoyancy flux, and\n",
    "$$J^\\text{buoy}_\\text{D} \\simeq f c_s \\frac{B_0}{H_\\text{ML}}$$\n",
    "where $c_s = 1.2$ comes from the assumption that that the turbulent vertical buoyancy flux divergence will remain similar, in some area-integrated sense, to classic upright convection ([Wenegrat et al., 2018](https://journals.ametsoc.org/doi/full/10.1175/JPO-D-17-0219.1)).\n",
    "The surface buoyancy flux is ([Buckingham et al., 2019](https://agupubs.onlinelibrary.wiley.com/doi/full/10.1029/2019MS001801)):\n",
    "$$B_0 = \\alpha g\\frac{Q_0}{\\rho_0 c_p} + \\beta g (E-P) S_0$$\n",
    "where $Q_0, E-P$ and $S_0$ are the surface net heat, fresh-water flux and salinity respectively. \n",
    "\n",
    "The fluxes are integrated in time only when and where the mode-water isopycnal outcrops at the surface. \n",
    "For simplicity and with prior knowledge that density is temperature dominated in the Gulf Stream region, we will define the mode water as waters with $18 \\pm 1 ^\\circ\\text{C}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/cnt0024/hmg2840/tuchida/condapack/lib/python3.7/site-packages/distributed/dashboard/core.py:72: UserWarning: \n",
      "Failed to start diagnostics server on port 8787. [Errno 13] Permission denied\n",
      "  warnings.warn(\"\\n\" + msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table style=\"border: 2px solid white;\">\n",
       "<tr>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Client</h3>\n",
       "<ul style=\"text-align: left; list-style: none; margin: 0; padding: 0;\">\n",
       "  <li><b>Scheduler: </b>tcp://127.0.0.1:37182</li>\n",
       "  <li><b>Dashboard: </b><a href='http://127.0.0.1:43250/status' target='_blank'>http://127.0.0.1:43250/status</a>\n",
       "</ul>\n",
       "</td>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Cluster</h3>\n",
       "<ul style=\"text-align: left; list-style:none; margin: 0; padding: 0;\">\n",
       "  <li><b>Workers: </b>12</li>\n",
       "  <li><b>Cores: </b>84</li>\n",
       "  <li><b>Memory: </b>405.28 GB</li>\n",
       "</ul>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Client: 'tcp://127.0.0.1:37182' processes=12 threads=84, memory=405.28 GB>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dask.distributed import Client, LocalCluster\n",
    "\n",
    "cluster = LocalCluster()\n",
    "cluster.scale(12)\n",
    "\n",
    "client = Client(cluster)\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "import xscale\n",
    "import gsw\n",
    "import os.path as op\n",
    "from xhistogram.xarray import histogram as xhist\n",
    "\n",
    "from matplotlib.gridspec import GridSpec\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddir = '/store/CT1/hmg2840/lbrodeau/eNATL60/eNATL60-BLBT02-S/'\n",
    "xtra = '/store/CT1/hmg2840/lbrodeau/eNATL60/eNATL60-BLBT02X-S'\n",
    "scratch = '/scratch/cnt0024/hmg2840/tuchida/temp'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ys,ye,xs,xe = (1400,2800,950,2550)\n",
    "g = 9.81\n",
    "cp = 4e3\n",
    "cs = 1.2\n",
    "zchunk = 10\n",
    "xchunk = -1\n",
    "ychunk = -1\n",
    "tchunk = -1\n",
    "\n",
    "gdepw = xr.open_dataset(op.join(scratch,'gdepw_eNATL60.nc')\n",
    "                       ).gdepw.sel(y=slice(ys,ye),x=slice(xs,xe)\n",
    "                                  ).chunk({'y':ychunk,'x':xchunk})\n",
    "dsmask = xr.open_dataset(op.join(ddir,'../eNATL60-I/mesh_mask_eNATL60_3.6.nc'), \n",
    "                         chunks={'z':zchunk,'y':ychunk,'x':xchunk}\n",
    "                        ).isel(y=slice(ys,ye),x=slice(xs,xe)).isel(t=0)\n",
    "f = xr.apply_ufunc(gsw.f, dsmask.nav_lat, dask='parallelized', output_dtypes=[float,])\n",
    "# f.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29] 1393201\n"
     ]
    }
   ],
   "source": [
    "# days = np.concatenate((np.arange(12,32,dtype=int), np.arange(1,6,dtype=int)))\n",
    "days = np.arange(6,30, dtype=int)\n",
    "dirs = 1393201\n",
    "print(days,dirs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Day: 10-27\n",
      "Day: 10-28\n",
      "Day: 10-29\n"
     ]
    }
   ],
   "source": [
    "month = 10\n",
    "year = 2010\n",
    "istart = -3\n",
    "\n",
    "for i in days[istart:]:\n",
    "    j = month\n",
    "    l = j\n",
    "    m = month+0\n",
    "#         if k > 0:\n",
    "#             j = m\n",
    "    if i < days[0]:\n",
    "        l = m\n",
    "            \n",
    "            \n",
    "    dsT = xr.open_dataset(op.join(xtra,'%08d-%08d/eNATL60-BLBT02X_1h_%4d%02d%02d_%4d%02d%02d_gridT_%4d%02d%02d-%4d%02d%02d.nc' \n",
    "                                  % (dirs,1440721,\n",
    "                                     # int(dirs+10800*len(days)*.2-1),\n",
    "                                     year,j,days[0],year,m,days[-1],\n",
    "                                     year,l,i,year,l,i)),\n",
    "                          chunks={'time_counter':tchunk,'deptht':zchunk,'y':ychunk,'x':xchunk}\n",
    "                         ).sel(deptht=slice(None,810))\n",
    "    dsS = xr.open_dataset(op.join(xtra,'%08d-%08d/eNATL60-BLBT02X_1h_%4d%02d%02d_%4d%02d%02d_gridS_%4d%02d%02d-%4d%02d%02d.nc' \n",
    "                                  % (dirs,1440721,\n",
    "                                     # int(dirs+10800*len(days)*.2-1),\n",
    "                                     year,j,days[0],year,m,days[-1],\n",
    "                                     year,l,i,year,l,i)),\n",
    "                          chunks={'time_counter':tchunk,'deptht':zchunk,'y':ychunk,'x':xchunk}\n",
    "                         ).sel(deptht=slice(None,810))\n",
    "    dsflx = xr.open_dataset(op.join(xtra,'%08d-%08d/eNATL60-BLBT02X_1h_%4d%02d%02d_%4d%02d%02d_flxT_%4d%02d%02d-%4d%02d%02d.nc'\n",
    "                                    % (dirs,1440721,\n",
    "                                       # int(dirs+10800*len(days)*.2-1),\n",
    "                                       year,j,days[0],year,m,days[-1],\n",
    "                                       year,l,i,year,l,i)),\n",
    "                            chunks={'time_counter':tchunk,'y':ychunk,'x':xchunk}\n",
    "                           )\n",
    "    dsH = xr.open_dataset(op.join(xtra,'%08d-%08d/eNATL60-BLBT02X_1h_%4d%02d%02d_%4d%02d%02d_gridT-2D_%4d%02d%02d-%4d%02d%02d.nc' \n",
    "                                  % (dirs,1440721,\n",
    "                                     # int(dirs+10800*len(days)*.2-1),\n",
    "                                     year,j,days[0],year,m,days[-1],\n",
    "                                     year,l,i,year,l,i)),\n",
    "                          chunks={'time_counter':tchunk,'y':ychunk,'x':xchunk}\n",
    "                         )\n",
    "    dsx = xr.open_dataset(op.join(xtra,'%08d-%08d/eNATL60-BLBT02X_1h_%4d%02d%02d_%4d%02d%02d_gridU-2D_%4d%02d%02d-%4d%02d%02d.nc' \n",
    "                                  % (dirs,1440721,\n",
    "                                     # int(dirs+10800*len(days)*.2-1),\n",
    "                                     year,j,days[0],year,m,days[-1],\n",
    "                                     year,l,i,year,l,i)),\n",
    "                          chunks={'time_counter':tchunk,'y':ychunk,'x':xchunk}\n",
    "                         )\n",
    "    dsy = xr.open_dataset(op.join(xtra,'%08d-%08d/eNATL60-BLBT02X_1h_%4d%02d%02d_%4d%02d%02d_gridV-2D_%4d%02d%02d-%4d%02d%02d.nc' \n",
    "                                  % (dirs,1440721,\n",
    "                                     # int(dirs+10800*len(days)*.2-1),\n",
    "                                     year,j,days[0],year,m,days[-1],\n",
    "                                     year,l,i,year,l,i)),\n",
    "                          chunks={'time_counter':tchunk,'y':ychunk,'x':xchunk}\n",
    "                         )\n",
    "        \n",
    "        \n",
    "    if i == days[istart]:\n",
    "        maskT = dsmask.tmask.isel(z=slice(None,len(dsT.deptht)))\n",
    "        maskU = dsmask.umask.isel(z=0)\n",
    "        maskV = dsmask.vmask.isel(z=0)\n",
    "        \n",
    "    for tt in range(len(dsflx.time_counter)):\n",
    "        CT = dsT.votemper.isel(y=slice(ys,ye),\n",
    "                               x=slice(xs,xe)).isel(time_counter=tt).where(xr.DataArray(maskT.data, \n",
    "                                                                                        dims=['deptht','y','x']) != 0.)\n",
    "        SA = dsS.vosaline.isel(y=slice(ys,ye),\n",
    "                               x=slice(xs,xe)).isel(time_counter=tt).where(xr.DataArray(maskT.data, \n",
    "                                                                                        dims=['deptht','y','x']) != 0.)\n",
    "        ssh = dsH.sossheig.isel(y=slice(ys,ye),\n",
    "                                x=slice(xs,xe)).isel(time_counter=tt).where(xr.DataArray(maskT.isel(z=0).data, \n",
    "                                                                                         dims=['y','x']) != 0.)\n",
    "        taux = dsx.sozotaux.isel(y=slice(ys,ye),\n",
    "                                 x=slice(xs,xe)).isel(time_counter=tt).where(xr.DataArray(maskU.data, \n",
    "                                                                                          dims=['y','x']) != 0.)\n",
    "        tauy = dsy.sometauy.isel(y=slice(ys,ye),\n",
    "                                 x=slice(xs,xe)).isel(time_counter=tt).where(xr.DataArray(maskV.data, \n",
    "                                                                                          dims=['y','x']) != 0.)\n",
    "\n",
    "\n",
    "        #     del dsT, dsS, dsW\n",
    "        sig0 = xr.apply_ufunc(gsw.sigma0, SA, CT, \n",
    "                              dask='parallelized', output_dtypes=[float,])\n",
    "        buoy = -g*sig0*1e-3\n",
    "        z10 = 6\n",
    "        nMLD = z10 + np.abs((sig0.isel(deptht=slice(z10,None)).fillna(999.)\n",
    "                             - sig0.isel(deptht=z10).fillna(999.)\n",
    "                            ) - 0.03).argmin(dim='deptht',skipna=True)\n",
    "        e3w = dsmask.e3w_0 * (1+ssh*gdepw**-1)\n",
    "        e3t = dsmask.e3t_0 * (1+ssh*gdepw**-1)\n",
    "\n",
    "        MLD = e3t.fillna(0.).where(e3t.z <= nMLD.fillna(0.).compute()\n",
    "                                  ).sum('z',skipna=True)\n",
    "\n",
    "        alpha = xr.apply_ufunc(gsw.alpha, SA.isel(deptht=0), CT.isel(deptht=0), 0.,\n",
    "                               dask='parallelized', output_dtypes=['float',])\n",
    "        beta = xr.apply_ufunc(gsw.beta, SA.isel(deptht=0), CT.isel(deptht=0), 0.,\n",
    "                              dask='parallelized', output_dtypes=['float',])\n",
    "        Bo = g*(-alpha * dsflx.qt_oce.isel(time_counter=tt).isel(y=slice(ys,ye),x=slice(xs,xe)) \n",
    "                * ((sig0.isel(deptht=0)+1e3)*cp)**-1\n",
    "                + beta * dsflx.sowaflup.isel(time_counter=tt).isel(y=slice(ys,ye),x=slice(xs,xe))\n",
    "                  * SA.isel(deptht=0)\n",
    "               )    # Positive values defined as destablizing conditions\n",
    "        \n",
    "        bx = (buoy.isel(x=slice(1,None))\n",
    "              + buoy.isel(x=slice(None,-1)).data\n",
    "             ) * .5\n",
    "        by = (buoy.isel(y=slice(1,None))\n",
    "              + buoy.isel(y=slice(None,-1)).data\n",
    "             ) * .5\n",
    "        dbx = bx.diff(dim='x') * dsmask.e1u.isel(x=slice(1,-1))**-1\n",
    "        dby = by.diff(dim='y') * dsmask.e2v.isel(y=slice(1,-1))**-1\n",
    "\n",
    "\n",
    "        dbx = (dbx.fillna(0.) * xr.DataArray(e3t.isel(z=slice(len(dsT.deptht))).isel(x=slice(1,-1)).data,\n",
    "                                             dims=['deptht','y','x'])\n",
    "              ).where(dbx.deptht <= MLD.isel(x=slice(1,-1))\n",
    "                     ).sum('deptht',skipna=True) * MLD.isel(x=slice(1,-1))**-1\n",
    "        dby = (dby.fillna(0.) * xr.DataArray(e3t.isel(z=slice(len(dsT.deptht))).isel(y=slice(1,-1)).data,\n",
    "                                             dims=['deptht','y','x'])\n",
    "              ).where(dby.deptht <= MLD.isel(y=slice(1,-1))\n",
    "                     ).sum('deptht',skipna=True) * MLD.isel(y=slice(1,-1))**-1\n",
    "        db2 = dbx.isel(y=slice(1,-1))**2 + dby.isel(x=slice(1,-1))**2\n",
    "\n",
    "#####################################\n",
    "        sst = CT.isel(deptht=0).load()\n",
    "\n",
    "        if tt == 0:\n",
    "            J_d = (Bo*f*cs*MLD**-1).compute().where(sst<19).where(sst>17)\n",
    "            J_ttw = -0.05*(MLD.isel(y=slice(1,-1),x=slice(1,-1)) * db2\n",
    "                          ).compute().where(sst.isel(y=slice(1,-1),x=slice(1,-1))<19\n",
    "                                           ).where(sst.isel(y=slice(1,-1),x=slice(1,-1))>17)\n",
    "            J_wind = ((.5*(tauy.isel(y=slice(1,None))+tauy.isel(y=slice(None,-1))).isel(y=slice(1,None),x=slice(1,-1)) \n",
    "                       * dbx.isel(y=slice(1,-1)) \n",
    "                       - .5*(taux.isel(x=slice(1,None))+taux.isel(x=slice(None,-1))).isel(y=slice(1,-1),x=slice(1,None)) \n",
    "                         * dby.isel(x=slice(1,-1))\n",
    "                      ) * ((sig0.fillna(0.)+1e3) * xr.DataArray(e3t[:len(dsT.deptht)].fillna(0.).data, \n",
    "                                                                dims=['deptht','y','x']\n",
    "                                                               )\n",
    "                          ).where(sig0.deptht <= MLD).isel(y=slice(1,-1),x=slice(1,-1)).sum('deptht',skipna=True)**-1\n",
    "                     ).compute().where(sst.isel(y=slice(1,-1),x=slice(1,-1))<19\n",
    "                                      ).where(sst.isel(y=slice(1,-1),x=slice(1,-1))>17)\n",
    "        else:\n",
    "            J_d = xr.concat([J_d, (Bo*f*cs*MLD**-1).compute().where(sst<19).where(sst>17)], \n",
    "                            'time_counter')\n",
    "            J_ttw = xr.concat([J_ttw, -0.05*(MLD.isel(y=slice(1,-1),x=slice(1,-1)) * db2\n",
    "                                            ).compute().where(sst.isel(y=slice(1,-1),x=slice(1,-1))<19\n",
    "                                                             ).where(sst.isel(y=slice(1,-1),x=slice(1,-1))>17)],\n",
    "                              'time_counter')\n",
    "            J_wind = xr.concat([J_wind, ((.5*(tauy.isel(y=slice(1,None))+tauy.isel(y=slice(None,-1))).isel(y=slice(1,None),\n",
    "                                                                                                           x=slice(1,-1)) \n",
    "                                          * dbx.isel(y=slice(1,-1)) \n",
    "                                          - .5*(taux.isel(x=slice(1,None))+taux.isel(x=slice(None,-1))).isel(y=slice(1,-1),\n",
    "                                                                                                             x=slice(1,None)) \n",
    "                                          * dby.isel(x=slice(1,-1))\n",
    "                                         ) * ((sig0.fillna(0.)+1e3) * xr.DataArray(e3t[:len(dsT.deptht)].fillna(0.).data, \n",
    "                                                                                   dims=['deptht','y','x']\n",
    "                                                                                  )\n",
    "                                             ).where(sig0.deptht <= MLD).isel(y=slice(1,-1),\n",
    "                                                                              x=slice(1,-1)).sum('deptht',skipna=True)**-1\n",
    "                                        ).compute().where(sst.isel(y=slice(1,-1),x=slice(1,-1))<19\n",
    "                                                         ).where(sst.isel(y=slice(1,-1),x=slice(1,-1))>17)],\n",
    "                                'time_counter')\n",
    "        \n",
    "        \n",
    "#         client.restart()\n",
    "    dsT.close()\n",
    "    dsS.close()\n",
    "    dsH.close()\n",
    "    dsflx.close()\n",
    "    dsx.close()\n",
    "    dsy.close() \n",
    "    \n",
    "    dsave = J_d.isel(y=slice(1,-1),x=slice(1,-1)).drop_vars('time_centered').to_dataset(name='J_D')\n",
    "    dsave['J_TTW'] = J_ttw.drop_vars('time_centered')\n",
    "    dsave['J_wind'] = J_wind.drop_vars('time_centered')\n",
    "#         dsave.coords['time_counter'] = ('time_counter', CT.time_counter.data)\n",
    "#         dsave['MLD'] = MLD_b\n",
    "    dsave.to_netcdf(op.join(scratch,'GulfStream/Jflux_%4d-%02d-%02d.nc' \n",
    "                                % (year,l,i)))\n",
    "    dsave.close()\n",
    "    print(r\"Day: %02d-%02d\" % (l,i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre>&lt;xarray.Dataset&gt;\n",
       "Dimensions:               (axis_nbounds: 2, time_counter: 24, x: 8354, y: 4729)\n",
       "Coordinates:\n",
       "    nav_lat               (y, x) float32 dask.array&lt;chunksize=(4729, 8354), meta=np.ndarray&gt;\n",
       "    nav_lon               (y, x) float32 dask.array&lt;chunksize=(4729, 8354), meta=np.ndarray&gt;\n",
       "    time_centered         (time_counter) datetime64[ns] dask.array&lt;chunksize=(24,), meta=np.ndarray&gt;\n",
       "  * time_counter          (time_counter) datetime64[ns] 2009-11-27T00:30:00 ... 2009-11-27T23:30:00\n",
       "Dimensions without coordinates: axis_nbounds, x, y\n",
       "Data variables:\n",
       "    time_centered_bounds  (time_counter, axis_nbounds) datetime64[ns] dask.array&lt;chunksize=(24, 2), meta=np.ndarray&gt;\n",
       "    time_counter_bounds   (time_counter, axis_nbounds) datetime64[ns] dask.array&lt;chunksize=(24, 2), meta=np.ndarray&gt;\n",
       "    sozocrtx              (time_counter, y, x) float32 dask.array&lt;chunksize=(24, 4729, 8354), meta=np.ndarray&gt;\n",
       "    bozocrtx              (time_counter, y, x) float32 dask.array&lt;chunksize=(24, 4729, 8354), meta=np.ndarray&gt;\n",
       "Attributes:\n",
       "    name:         /scratch/tmp/5153313/eNATL60-BLBT02X_1h_20091127_20091221_g...\n",
       "    description:  ocean U grid variables\n",
       "    title:        ocean U grid variables\n",
       "    Conventions:  CF-1.6\n",
       "    timeStamp:    2019-Mar-14 01:39:53 GMT\n",
       "    uuid:         624d14d4-f616-4ee5-a52b-f8860f37f747\n",
       "    ibegin:       0\n",
       "    ni:           8354\n",
       "    jbegin:       0\n",
       "    nj:           10\n",
       "    file_name:    eNATL60-BLBT02X_1h_20091127_20091221_gridU-2D_20091127-2009...\n",
       "    TimeStamp:    18/03/2019 09:39:46 +0100</pre>"
      ],
      "text/plain": [
       "<xarray.Dataset>\n",
       "Dimensions:               (axis_nbounds: 2, time_counter: 24, x: 8354, y: 4729)\n",
       "Coordinates:\n",
       "    nav_lat               (y, x) float32 dask.array<chunksize=(4729, 8354), meta=np.ndarray>\n",
       "    nav_lon               (y, x) float32 dask.array<chunksize=(4729, 8354), meta=np.ndarray>\n",
       "    time_centered         (time_counter) datetime64[ns] dask.array<chunksize=(24,), meta=np.ndarray>\n",
       "  * time_counter          (time_counter) datetime64[ns] 2009-11-27T00:30:00 ... 2009-11-27T23:30:00\n",
       "Dimensions without coordinates: axis_nbounds, x, y\n",
       "Data variables:\n",
       "    time_centered_bounds  (time_counter, axis_nbounds) datetime64[ns] dask.array<chunksize=(24, 2), meta=np.ndarray>\n",
       "    time_counter_bounds   (time_counter, axis_nbounds) datetime64[ns] dask.array<chunksize=(24, 2), meta=np.ndarray>\n",
       "    sozocrtx              (time_counter, y, x) float32 dask.array<chunksize=(24, 4729, 8354), meta=np.ndarray>\n",
       "    bozocrtx              (time_counter, y, x) float32 dask.array<chunksize=(24, 4729, 8354), meta=np.ndarray>\n",
       "Attributes:\n",
       "    name:         /scratch/tmp/5153313/eNATL60-BLBT02X_1h_20091127_20091221_g...\n",
       "    description:  ocean U grid variables\n",
       "    title:        ocean U grid variables\n",
       "    Conventions:  CF-1.6\n",
       "    timeStamp:    2019-Mar-14 01:39:53 GMT\n",
       "    uuid:         624d14d4-f616-4ee5-a52b-f8860f37f747\n",
       "    ibegin:       0\n",
       "    ni:           8354\n",
       "    jbegin:       0\n",
       "    nj:           10\n",
       "    file_name:    eNATL60-BLBT02X_1h_20091127_20091221_gridU-2D_20091127-2009...\n",
       "    TimeStamp:    18/03/2019 09:39:46 +0100"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dsx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre>&lt;xarray.DataArray &#x27;time_counter&#x27; (time_counter: 576)&gt;\n",
       "array([&#x27;2010-04-11T00:30:00.000000000&#x27;, &#x27;2010-04-11T01:30:00.000000000&#x27;,\n",
       "       &#x27;2010-04-11T02:30:00.000000000&#x27;, ..., &#x27;2010-04-11T21:30:00.000000000&#x27;,\n",
       "       &#x27;2010-04-11T22:30:00.000000000&#x27;, &#x27;2010-04-11T23:30:00.000000000&#x27;],\n",
       "      dtype=&#x27;datetime64[ns]&#x27;)\n",
       "Coordinates:\n",
       "    deptht         float64 0.4805\n",
       "  * time_counter   (time_counter) datetime64[ns] 2010-04-11T00:30:00 ... 2010-04-11T23:30:00\n",
       "    time_centered  (time_counter) datetime64[ns] 2010-04-11T00:30:00 ... 2010-04-11T23:30:00\n",
       "Attributes:\n",
       "    axis:           T\n",
       "    standard_name:  time\n",
       "    long_name:      Time axis\n",
       "    time_origin:    1900-01-01 00:00:00\n",
       "    bounds:         time_counter_bounds</pre>"
      ],
      "text/plain": [
       "<xarray.DataArray 'time_counter' (time_counter: 576)>\n",
       "array(['2010-04-11T00:30:00.000000000', '2010-04-11T01:30:00.000000000',\n",
       "       '2010-04-11T02:30:00.000000000', ..., '2010-04-11T21:30:00.000000000',\n",
       "       '2010-04-11T22:30:00.000000000', '2010-04-11T23:30:00.000000000'],\n",
       "      dtype='datetime64[ns]')\n",
       "Coordinates:\n",
       "    deptht         float64 0.4805\n",
       "  * time_counter   (time_counter) datetime64[ns] 2010-04-11T00:30:00 ... 2010-04-11T23:30:00\n",
       "    time_centered  (time_counter) datetime64[ns] 2010-04-11T00:30:00 ... 2010-04-11T23:30:00\n",
       "Attributes:\n",
       "    axis:           T\n",
       "    standard_name:  time\n",
       "    long_name:      Time axis\n",
       "    time_origin:    1900-01-01 00:00:00\n",
       "    bounds:         time_counter_bounds"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "J_d.time_counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre>&lt;xarray.DataArray &#x27;time_counter&#x27; (time_counter: 24)&gt;\n",
       "array([&#x27;2010-04-11T00:30:00.000000000&#x27;, &#x27;2010-04-11T01:30:00.000000000&#x27;,\n",
       "       &#x27;2010-04-11T02:30:00.000000000&#x27;, &#x27;2010-04-11T03:30:00.000000000&#x27;,\n",
       "       &#x27;2010-04-11T04:30:00.000000000&#x27;, &#x27;2010-04-11T05:30:00.000000000&#x27;,\n",
       "       &#x27;2010-04-11T06:30:00.000000000&#x27;, &#x27;2010-04-11T07:30:00.000000000&#x27;,\n",
       "       &#x27;2010-04-11T08:30:00.000000000&#x27;, &#x27;2010-04-11T09:30:00.000000000&#x27;,\n",
       "       &#x27;2010-04-11T10:30:00.000000000&#x27;, &#x27;2010-04-11T11:30:00.000000000&#x27;,\n",
       "       &#x27;2010-04-11T12:30:00.000000000&#x27;, &#x27;2010-04-11T13:30:00.000000000&#x27;,\n",
       "       &#x27;2010-04-11T14:30:00.000000000&#x27;, &#x27;2010-04-11T15:30:00.000000000&#x27;,\n",
       "       &#x27;2010-04-11T16:30:00.000000000&#x27;, &#x27;2010-04-11T17:30:00.000000000&#x27;,\n",
       "       &#x27;2010-04-11T18:30:00.000000000&#x27;, &#x27;2010-04-11T19:30:00.000000000&#x27;,\n",
       "       &#x27;2010-04-11T20:30:00.000000000&#x27;, &#x27;2010-04-11T21:30:00.000000000&#x27;,\n",
       "       &#x27;2010-04-11T22:30:00.000000000&#x27;, &#x27;2010-04-11T23:30:00.000000000&#x27;],\n",
       "      dtype=&#x27;datetime64[ns]&#x27;)\n",
       "Coordinates:\n",
       "    time_centered  (time_counter) datetime64[ns] dask.array&lt;chunksize=(24,), meta=np.ndarray&gt;\n",
       "  * time_counter   (time_counter) datetime64[ns] 2010-04-11T00:30:00 ... 2010-04-11T23:30:00\n",
       "Attributes:\n",
       "    axis:           T\n",
       "    standard_name:  time\n",
       "    long_name:      Time axis\n",
       "    time_origin:    1900-01-01 00:00:00\n",
       "    bounds:         time_counter_bounds</pre>"
      ],
      "text/plain": [
       "<xarray.DataArray 'time_counter' (time_counter: 24)>\n",
       "array(['2010-04-11T00:30:00.000000000', '2010-04-11T01:30:00.000000000',\n",
       "       '2010-04-11T02:30:00.000000000', '2010-04-11T03:30:00.000000000',\n",
       "       '2010-04-11T04:30:00.000000000', '2010-04-11T05:30:00.000000000',\n",
       "       '2010-04-11T06:30:00.000000000', '2010-04-11T07:30:00.000000000',\n",
       "       '2010-04-11T08:30:00.000000000', '2010-04-11T09:30:00.000000000',\n",
       "       '2010-04-11T10:30:00.000000000', '2010-04-11T11:30:00.000000000',\n",
       "       '2010-04-11T12:30:00.000000000', '2010-04-11T13:30:00.000000000',\n",
       "       '2010-04-11T14:30:00.000000000', '2010-04-11T15:30:00.000000000',\n",
       "       '2010-04-11T16:30:00.000000000', '2010-04-11T17:30:00.000000000',\n",
       "       '2010-04-11T18:30:00.000000000', '2010-04-11T19:30:00.000000000',\n",
       "       '2010-04-11T20:30:00.000000000', '2010-04-11T21:30:00.000000000',\n",
       "       '2010-04-11T22:30:00.000000000', '2010-04-11T23:30:00.000000000'],\n",
       "      dtype='datetime64[ns]')\n",
       "Coordinates:\n",
       "    time_centered  (time_counter) datetime64[ns] dask.array<chunksize=(24,), meta=np.ndarray>\n",
       "  * time_counter   (time_counter) datetime64[ns] 2010-04-11T00:30:00 ... 2010-04-11T23:30:00\n",
       "Attributes:\n",
       "    axis:           T\n",
       "    standard_name:  time\n",
       "    long_name:      Time axis\n",
       "    time_origin:    1900-01-01 00:00:00\n",
       "    bounds:         time_counter_bounds"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dsT.time_counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
